'use client';

import React, { useRef, useEffect, useState, useCallback } from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '../ui/Card';
import { ActionButton } from '../ui/ActionButton';
import { 
  Camera, 
  Mic, 
  MicOff, 
  Video, 
  VideoOff, 
  Phone, 
  PhoneOff,
  Settings,
  Maximize2,
  Minimize2,
  MessageSquare,
  Brain,
  Activity
} from 'lucide-react';
import { VADScore, EmotionAnalysis } from '../../types';
import { emotionEmojis } from '../../utils/emotion';

interface VideoCallEmotionAnalysisProps {
  onEmotionChange?: (emotion: EmotionAnalysis) => void;
  onCallEnd?: () => void;
  isActive?: boolean;
}

export default function VideoCallEmotionAnalysis({ 
  onEmotionChange, 
  onCallEnd,
  isActive = false 
}: VideoCallEmotionAnalysisProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  
  // ìƒíƒœ ê´€ë¦¬
  const [isVideoOn, setIsVideoOn] = useState(true);
  const [isAudioOn, setIsAudioOn] = useState(true);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isFullscreen, setIsFullscreen] = useState(false);
  const [currentEmotion, setCurrentEmotion] = useState<EmotionAnalysis | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);
  
  // ì‚¬ìš©ì ì¹œí™”ì ì¸ ìƒíƒœ ê´€ë¦¬
  const [callStatus, setCallStatus] = useState<'connecting' | 'connected' | 'analyzing' | 'paused' | 'ended'>('connecting');
  const [recordingTime, setRecordingTime] = useState(0);
  const [showGuide, setShowGuide] = useState(true);
  const [permissionGranted, setPermissionGranted] = useState(false);
  
  // ì‹¤ì‹œê°„ ë¶„ì„ ìƒíƒœ
  const [facialVAD, setFacialVAD] = useState<VADScore>({ valence: 0.5, arousal: 0.5, dominance: 0.5 });
  const [voiceVAD, setVoiceVAD] = useState<VADScore>({ valence: 0.5, arousal: 0.5, dominance: 0.5 });
  const [confidence, setConfidence] = useState(0);

  const animationFrameRef = useRef<number | null>(null);
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null);

  // ë…¹í™” íƒ€ì´ë¨¸ ì‹œì‘
  const startRecordingTimer = useCallback(() => {
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
    }
    recordingTimerRef.current = setInterval(() => {
      setRecordingTime(prev => prev + 1);
    }, 1000);
  }, []);

  // ë…¹í™” íƒ€ì´ë¨¸ ì •ì§€
  const stopRecordingTimer = useCallback(() => {
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }
  }, []);

  // ì‹œê°„ í¬ë§·íŒ…
  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
  const initializeMediaStream = useCallback(async () => {
    try {
      setCallStatus('connecting');
      setError(null);
      
      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        },
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      setStream(mediaStream);
      setPermissionGranted(true);
      setCallStatus('connected');
      
      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
      }

      // ì˜¤ë””ì˜¤ ë¶„ì„ ì´ˆê¸°í™”
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      }

      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 2048;
      analyserRef.current.smoothingTimeConstant = 0.8;

      microphoneRef.current = audioContextRef.current.createMediaStreamSource(mediaStream);
      microphoneRef.current.connect(analyserRef.current);

      return true;
    } catch (err) {
      console.error('ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” ì‹¤íŒ¨:', err);
      setError('ì¹´ë©”ë¼ë‚˜ ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      setCallStatus('ended');
      return false;
    }
  }, []);

  // ì‹¤ì‹œê°„ ê°ì • ë¶„ì„
  const analyzeEmotion = useCallback(() => {
    if (!isAnalyzing) return;

    let currentVoiceVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };
    let currentFacialVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };

    // ìŒì„± ë¶„ì„
    if (analyserRef.current && isAudioOn) {
      const bufferLength = analyserRef.current.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      const timeDataArray = new Uint8Array(bufferLength);

      analyserRef.current.getByteFrequencyData(dataArray);
      analyserRef.current.getByteTimeDomainData(timeDataArray);

      const volumeLevel = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength / 255;
      const pitchValue = calculatePitch(timeDataArray);
      const rateValue = calculateSpeechRate(timeDataArray);

      currentVoiceVAD = calculateVoiceVAD(volumeLevel, pitchValue, rateValue);
    }

    // í‘œì • ë¶„ì„ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
    if (isVideoOn) {
      currentFacialVAD = calculateFacialVAD();
    }

    // í†µí•© VAD ì ìˆ˜ ê³„ì‚°
    const integratedVAD = calculateIntegratedVAD(currentFacialVAD, currentVoiceVAD);
    const emotion = vadToEmotion(integratedVAD);
    const confidenceScore = calculateConfidence(currentFacialVAD, currentVoiceVAD);

    const emotionAnalysis: EmotionAnalysis = {
      id: `realtime_${Date.now()}`,
      userId: 'user123',
      timestamp: new Date().toISOString(),
      vadScore: integratedVAD,
      emotion,
      confidence: confidenceScore,
      mediaType: 'realtime',
      cbtFeedback: {
        cognitiveDistortion: 'ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘',
        challenge: 'í˜„ì¬ ê°ì • ìƒíƒœë¥¼ ê´€ì°°í•´ë³´ì„¸ìš”',
        alternative: 'ê°ì • ë³€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°›ì•„ë“¤ì´ì„¸ìš”',
        actionPlan: 'ì •ê¸°ì ì¸ ê°ì • ì²´í¬ë¥¼ í•´ë³´ì„¸ìš”'
      }
    };

    // ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
    setVoiceVAD(currentVoiceVAD);
    setFacialVAD(currentFacialVAD);
    setCurrentEmotion(emotionAnalysis);
    setConfidence(confidenceScore);

    if (onEmotionChange) {
      onEmotionChange(emotionAnalysis);
    }

    animationFrameRef.current = requestAnimationFrame(analyzeEmotion);
  }, [isAnalyzing, isAudioOn, isVideoOn, onEmotionChange]);

  // í”¼ì¹˜ ê³„ì‚°
  const calculatePitch = (timeData: Uint8Array): number => {
    let sum = 0;
    let count = 0;
    
    for (let i = 0; i < timeData.length; i++) {
      const value = (timeData[i] - 128) / 128;
      sum += Math.abs(value);
      count++;
    }
    
    return count > 0 ? sum / count : 0;
  };

  // ìŒì„± ì†ë„ ê³„ì‚°
  const calculateSpeechRate = (timeData: Uint8Array): number => {
    let zeroCrossings = 0;
    
    for (let i = 1; i < timeData.length; i++) {
      const prev = (timeData[i - 1] - 128) / 128;
      const curr = (timeData[i] - 128) / 128;
      
      if ((prev < 0 && curr >= 0) || (prev >= 0 && curr < 0)) {
        zeroCrossings++;
      }
    }
    
    return zeroCrossings / timeData.length;
  };

  // ìŒì„± VAD ê³„ì‚°
  const calculateVoiceVAD = (volume: number, pitch: number, rate: number): VADScore => {
    return {
      valence: Math.min(1, Math.max(0, 0.5 + (pitch - 0.5) * 0.3)),
      arousal: Math.min(1, Math.max(0, volume * 0.8 + rate * 0.2)),
      dominance: Math.min(1, Math.max(0, 0.5 + (volume - 0.5) * 0.4))
    };
  };

  // í‘œì • VAD ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
  const calculateFacialVAD = (): VADScore => {
    // ì‹¤ì œë¡œëŠ” MediaPipe Face Meshë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
    return {
      valence: 0.5 + (Math.random() - 0.5) * 0.2,
      arousal: 0.5 + (Math.random() - 0.5) * 0.2,
      dominance: 0.5 + (Math.random() - 0.5) * 0.2
    };
  };

  // í†µí•© VAD ê³„ì‚°
  const calculateIntegratedVAD = (facial: VADScore, voice: VADScore): VADScore => {
    return {
      valence: (facial.valence * 0.6 + voice.valence * 0.4),
      arousal: (facial.arousal * 0.4 + voice.arousal * 0.6),
      dominance: (facial.dominance * 0.5 + voice.dominance * 0.5)
    };
  };

  // VADë¥¼ ê°ì •ìœ¼ë¡œ ë³€í™˜
  const vadToEmotion = (vad: VADScore): string => {
    const { valence, arousal, dominance } = vad;
    
    if (valence > 0.7 && arousal > 0.7) return 'excited';
    if (valence > 0.7 && arousal < 0.3) return 'calm';
    if (valence > 0.6) return 'happy';
    if (valence < 0.4 && arousal > 0.7) return 'angry';
    if (valence < 0.4 && arousal < 0.3) return 'sad';
    if (dominance < 0.4 && arousal > 0.6) return 'anxious';
    
    return 'neutral';
  };

  // ì‹ ë¢°ë„ ê³„ì‚°
  const calculateConfidence = (facial: VADScore, voice: VADScore): number => {
    const facialConfidence = 0.8; // ì‹¤ì œë¡œëŠ” ì–¼êµ´ ì¸ì‹ ì‹ ë¢°ë„
    const voiceConfidence = 0.7; // ì‹¤ì œë¡œëŠ” ìŒì„± í’ˆì§ˆ ì‹ ë¢°ë„
    return (facialConfidence * 0.6 + voiceConfidence * 0.4);
  };



  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì´ˆê¸°í™”
  useEffect(() => {
    if (isActive) {
      initializeMediaStream();
    }
  }, [isActive, initializeMediaStream]);

  // ë¶„ì„ ë£¨í”„ ì‹œì‘/ì¤‘ì§€
  useEffect(() => {
    let isActive = isAnalyzing;
    
    if (isActive) {
      const runAnalysis = () => {
        if (!isActive) return;
        
        let currentVoiceVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };
        let currentFacialVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };

        // ìŒì„± ë¶„ì„
        if (analyserRef.current && isAudioOn) {
          const bufferLength = analyserRef.current.frequencyBinCount;
          const dataArray = new Uint8Array(bufferLength);
          const timeDataArray = new Uint8Array(bufferLength);

          analyserRef.current.getByteFrequencyData(dataArray);
          analyserRef.current.getByteTimeDomainData(timeDataArray);

          const volumeLevel = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength / 255;
          const pitchValue = calculatePitch(timeDataArray);
          const rateValue = calculateSpeechRate(timeDataArray);

          currentVoiceVAD = calculateVoiceVAD(volumeLevel, pitchValue, rateValue);
        }

        // í‘œì • ë¶„ì„ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
        if (isVideoOn) {
          currentFacialVAD = calculateFacialVAD();
        }

        // í†µí•© VAD ì ìˆ˜ ê³„ì‚°
        const integratedVAD = calculateIntegratedVAD(currentFacialVAD, currentVoiceVAD);
        const emotion = vadToEmotion(integratedVAD);
        const confidenceScore = calculateConfidence(currentFacialVAD, currentVoiceVAD);

        const emotionAnalysis: EmotionAnalysis = {
          id: `realtime_${Date.now()}`,
          userId: 'user123',
          timestamp: new Date().toISOString(),
          vadScore: integratedVAD,
          emotion,
          confidence: confidenceScore,
          mediaType: 'realtime',
          cbtFeedback: {
            cognitiveDistortion: 'ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘',
            challenge: 'í˜„ì¬ ê°ì • ìƒíƒœë¥¼ ê´€ì°°í•´ë³´ì„¸ìš”',
            alternative: 'ê°ì • ë³€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°›ì•„ë“¤ì´ì„¸ìš”',
            actionPlan: 'ì •ê¸°ì ì¸ ê°ì • ì²´í¬ë¥¼ í•´ë³´ì„¸ìš”'
          }
        };

        setCurrentEmotion(emotionAnalysis);
        setConfidence(confidenceScore);

        if (onEmotionChange) {
          onEmotionChange(emotionAnalysis);
        }

        if (isActive) {
          animationFrameRef.current = requestAnimationFrame(runAnalysis);
        }
      };

      runAnalysis();
    } else if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }

    return () => {
      isActive = false;
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [isAnalyzing, isAudioOn, isVideoOn]);

  // ë¶„ì„ í† ê¸€
  const toggleAnalysis = useCallback(() => {
    if (!permissionGranted) {
      setError('ë¨¼ì € ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsAnalyzing(prev => {
      const newState = !prev;
      if (newState) {
        setCallStatus('analyzing');
        startRecordingTimer();
        setShowGuide(false);
      } else {
        setCallStatus('paused');
        stopRecordingTimer();
      }
      return newState;
    });
  }, [permissionGranted, startRecordingTimer, stopRecordingTimer]);

  // ë¹„ë””ì˜¤ í† ê¸€
  const toggleVideo = useCallback(() => {
    if (stream) {
      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !isVideoOn;
        setIsVideoOn(!isVideoOn);
      }
    }
  }, [stream, isVideoOn]);

  // ì˜¤ë””ì˜¤ í† ê¸€
  const toggleAudio = useCallback(() => {
    if (stream) {
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !isAudioOn;
        setIsAudioOn(!isAudioOn);
      }
    }
  }, [stream, isAudioOn]);

  // ì „ì²´í™”ë©´ í† ê¸€
  const toggleFullscreen = useCallback(() => {
    if (!document.fullscreenElement) {
      document.documentElement.requestFullscreen();
      setIsFullscreen(true);
    } else {
      document.exitFullscreen();
      setIsFullscreen(false);
    }
  }, []);

  // ìƒë‹´ ì¢…ë£Œ
  const endCall = useCallback(() => {
    setCallStatus('ended');
    stopRecordingTimer();
    setIsAnalyzing(false);
    
    // ìƒë‹´ ì¢…ë£Œ í›„ ë¶„ì„ ê²°ê³¼ ìƒì„±
    if (currentEmotion && onEmotionChange) {
      const finalAnalysis: EmotionAnalysis = {
        ...currentEmotion,
        id: `consultation_${Date.now()}`,
        timestamp: new Date().toISOString(),
        mediaType: 'consultation',
        cbtFeedback: {
          cognitiveDistortion: 'ìƒë‹´ì„ í†µí•´ ê°ì • ìƒíƒœë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤',
          challenge: 'í˜„ì¬ ê°ì • ìƒíƒœë¥¼ ê°ê´€ì ìœ¼ë¡œ ë°”ë¼ë³´ì„¸ìš”',
          alternative: 'ê°ì • ë³€í™”ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ê³¼ì •ì…ë‹ˆë‹¤',
          actionPlan: 'ì •ê¸°ì ì¸ ê°ì • ì²´í¬ì™€ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤'
        }
      };
      onEmotionChange(finalAnalysis);
    }
    
    if (onCallEnd) {
      onCallEnd();
    }
  }, [onCallEnd, stopRecordingTimer, currentEmotion, onEmotionChange]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
  useEffect(() => {
    if (isActive) {
      initializeMediaStream();
    }
  }, [isActive, initializeMediaStream]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopRecordingTimer();
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        try {
          audioContextRef.current.close();
        } catch (error) {
          console.warn('AudioContext already closed:', error);
        }
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [stream, stopRecordingTimer]);

  if (!isActive) {
    return null;
  }

  return (
    <div className="relative w-full h-full bg-black rounded-lg overflow-hidden">
      {/* ë¹„ë””ì˜¤ ì˜ì—­ */}
      <div className="relative w-full h-full">
        <video
          ref={videoRef}
          className="w-full h-full object-cover transform scale-x-[-1]"
          autoPlay
          muted
          playsInline
        />
        <canvas
          ref={canvasRef}
          className="absolute inset-0 w-full h-full pointer-events-none"
        />
        
        {/* ìƒíƒœ í‘œì‹œ ì˜¤ë²„ë ˆì´ */}
        <div className="absolute top-4 left-4 bg-black bg-opacity-70 text-white px-4 py-3 rounded-xl backdrop-blur-sm">
          <div className="flex items-center space-x-3">
            <div className={`w-3 h-3 rounded-full ${
              callStatus === 'connecting' ? 'bg-yellow-400 animate-pulse' :
              callStatus === 'connected' ? 'bg-green-400' :
              callStatus === 'analyzing' ? 'bg-red-400 animate-pulse' :
              callStatus === 'paused' ? 'bg-orange-400' :
              'bg-gray-400'
            }`} />
            <div className="text-sm font-medium">
              {callStatus === 'connecting' && 'ì—°ê²° ì¤‘...'}
              {callStatus === 'connected' && 'ì—°ê²°ë¨'}
              {callStatus === 'analyzing' && 'ë¶„ì„ ì¤‘'}
              {callStatus === 'paused' && 'ì¼ì‹œì •ì§€'}
              {callStatus === 'ended' && 'ì¢…ë£Œë¨'}
            </div>
          </div>
          {isAnalyzing && (
            <div className="mt-2 text-xs text-gray-300">
              ë…¹í™” ì‹œê°„: {formatTime(recordingTime)}
            </div>
          )}
        </div>

        {/* í˜„ì¬ ê°ì • í‘œì‹œ */}
        {currentEmotion && isAnalyzing && (
          <div className="absolute top-4 right-4 bg-black bg-opacity-70 text-white px-4 py-3 rounded-xl backdrop-blur-sm">
            <div className="flex items-center space-x-3">
              <span className="text-2xl">{emotionEmojis[currentEmotion.emotion as keyof typeof emotionEmojis] || 'ğŸ˜'}</span>
              <div className="text-sm">
                <div className="font-medium">{currentEmotion.emotion === 'happy' ? 'ê¸°ì¨' : 
                  currentEmotion.emotion === 'sad' ? 'ìŠ¬í””' :
                  currentEmotion.emotion === 'angry' ? 'ë¶„ë…¸' :
                  currentEmotion.emotion === 'surprised' ? 'ë†€ëŒ' : 'ì¤‘ë¦½'}</div>
                <div className="text-xs text-gray-300">
                  ì‹ ë¢°ë„: {Math.round(confidence * 100)}%
                </div>
              </div>
            </div>
          </div>
        )}

        {/* ì‚¬ìš©ì ê°€ì´ë“œ */}
        {showGuide && callStatus === 'connected' && (
          <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 bg-black bg-opacity-80 text-white px-6 py-4 rounded-xl backdrop-blur-sm max-w-md text-center">
            <div className="space-y-3">
              <div className="text-lg font-semibold">ğŸ¥ ì˜ìƒ ìƒë‹´ ê°ì • ë¶„ì„</div>
              <div className="text-sm text-gray-300 space-y-2">
                <p>â€¢ ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤</p>
                <p>â€¢ "ì•Œê² ìŠµë‹ˆë‹¤" ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë°”ë¡œ ê°ì • ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤</p>
                <p>â€¢ ë¶„ì„ ì¤‘ì—ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì •ì´ í‘œì‹œë©ë‹ˆë‹¤</p>
                <p>â€¢ ì–¸ì œë“ ì§€ "ì¼ì‹œì •ì§€" ë˜ëŠ” "ìƒë‹´ ì¢…ë£Œ"í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</p>
              </div>
              <button
                onClick={() => {
                  setShowGuide(false);
                  // ë°”ë¡œ ë¶„ì„ ì‹œì‘
                  if (permissionGranted) {
                    setIsAnalyzing(true);
                    setCallStatus('analyzing');
                    startRecordingTimer();
                  }
                }}
                className="mt-4 px-4 py-2 bg-primary text-white rounded-lg text-sm hover:bg-primary-dark transition-colors"
              >
                ì•Œê² ìŠµë‹ˆë‹¤
              </button>
            </div>
          </div>
        )}

        {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
        {error && (
          <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 bg-red-500 text-white px-6 py-4 rounded-xl max-w-md text-center backdrop-blur-sm">
            <div className="space-y-2">
              <div className="text-lg font-semibold">âš ï¸ ì˜¤ë¥˜ ë°œìƒ</div>
              <div className="text-sm">{error}</div>
              <button
                onClick={() => setError(null)}
                className="mt-3 px-4 py-2 bg-white text-red-500 rounded-lg text-sm hover:bg-gray-100 transition-colors"
              >
                í™•ì¸
              </button>
            </div>
          </div>
        )}

        {/* ë…¹í™” ìƒíƒœ í‘œì‹œ */}
        {isAnalyzing && (
          <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2">
            <div className="bg-red-500 text-white px-3 py-1 rounded-full text-sm font-medium animate-pulse">
              ğŸ”´ ë…¹í™” ì¤‘
            </div>
          </div>
        )}

        {/* ì»¨íŠ¸ë¡¤ ë°” */}
        <div className="absolute bottom-6 left-1/2 transform -translate-x-1/2 bg-black bg-opacity-70 rounded-full px-8 py-4 backdrop-blur-sm">
          <div className="flex items-center space-x-4">
            {/* ë¶„ì„ í† ê¸€ - ìƒë‹´ ì‹œì‘ í›„ì—ë§Œ í‘œì‹œ */}
            {isAnalyzing && (
              <ActionButton
                variant="danger"
                size="sm"
                onClick={toggleAnalysis}
                className="flex flex-col items-center space-y-1"
              >
                <Brain className="w-4 h-4" />
                <span className="text-xs">ì¼ì‹œì •ì§€</span>
              </ActionButton>
            )}

            {/* ë¹„ë””ì˜¤ í† ê¸€ */}
            <ActionButton
              variant={isVideoOn ? 'secondary' : 'danger'}
              size="sm"
              onClick={toggleVideo}
              className="flex flex-col items-center space-y-1"
            >
              {isVideoOn ? <Video className="w-4 h-4" /> : <VideoOff className="w-4 h-4" />}
              <span className="text-xs">{isVideoOn ? 'ì¹´ë©”ë¼ ë„ê¸°' : 'ì¹´ë©”ë¼ ì¼œê¸°'}</span>
            </ActionButton>

            {/* ì˜¤ë””ì˜¤ í† ê¸€ */}
            <ActionButton
              variant={isAudioOn ? 'secondary' : 'danger'}
              size="sm"
              onClick={toggleAudio}
              className="flex flex-col items-center space-y-1"
            >
              {isAudioOn ? <Mic className="w-4 h-4" /> : <MicOff className="w-4 h-4" />}
              <span className="text-xs">{isAudioOn ? 'ë§ˆì´í¬ ë„ê¸°' : 'ë§ˆì´í¬ ì¼œê¸°'}</span>
            </ActionButton>

            {/* ì „ì²´í™”ë©´ í† ê¸€ */}
            <ActionButton
              variant="secondary"
              size="sm"
              onClick={toggleFullscreen}
              className="flex flex-col items-center space-y-1"
            >
              {isFullscreen ? <Minimize2 className="w-4 h-4" /> : <Maximize2 className="w-4 h-4" />}
              <span className="text-xs">{isFullscreen ? 'ì „ì²´í™”ë©´ í•´ì œ' : 'ì „ì²´í™”ë©´'}</span>
            </ActionButton>

            {/* ìƒë‹´ ì¢…ë£Œ - ìƒë‹´ ì‹œì‘ í›„ì—ë§Œ í‘œì‹œ */}
            {isAnalyzing && (
              <ActionButton
                variant="danger"
                size="sm"
                onClick={endCall}
                className="flex flex-col items-center space-y-1"
              >
                <PhoneOff className="w-4 h-4" />
                <span className="text-xs">ìƒë‹´ ì¢…ë£Œ</span>
              </ActionButton>
            )}
          </div>
        </div>
      </div>
    </div>
  );
} 