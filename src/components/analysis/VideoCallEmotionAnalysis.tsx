'use client';

import React, { useRef, useEffect, useState, useCallback, useMemo } from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '../ui/Card';
import { ActionButton } from '../ui/ActionButton';
import { 
  Camera, 
  Mic, 
  MicOff, 
  Video, 
  VideoOff, 
  Phone, 
  PhoneOff,
  Settings,
  MessageSquare,
  Brain,
  Activity
} from 'lucide-react';
import { VADScore, EmotionAnalysis } from '../../types';
import { emotionEmojis } from '../../utils/emotion';
import { emotionRepository } from '../../services/repositories/emotionRepository';

interface VideoCallEmotionAnalysisProps {
  onEmotionChange?: (emotion: EmotionAnalysis) => void;
  onCallEnd?: () => void;
  isActive?: boolean;
}

export default function VideoCallEmotionAnalysis({ 
  onEmotionChange, 
  onCallEnd,
  isActive = false 
}: VideoCallEmotionAnalysisProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  
  // ìƒíƒœ ê´€ë¦¬
  const [isVideoOn, setIsVideoOn] = useState(true);
  const [isAudioOn, setIsAudioOn] = useState(true);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [currentEmotion, setCurrentEmotion] = useState<EmotionAnalysis | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);
  
  // ì‚¬ìš©ì ì¹œí™”ì ì¸ ìƒíƒœ ê´€ë¦¬
  const [callStatus, setCallStatus] = useState<'connecting' | 'connected' | 'analyzing' | 'paused' | 'ended'>('connecting');
  const [recordingTime, setRecordingTime] = useState(0);
  const [showGuide, setShowGuide] = useState(true);
  const [permissionGranted, setPermissionGranted] = useState(false);
  
  // ì‹¤ì‹œê°„ ë¶„ì„ ìƒíƒœ
  const [facialVAD, setFacialVAD] = useState<VADScore>({ valence: 0.5, arousal: 0.5, dominance: 0.5 });
  const [voiceVAD, setVoiceVAD] = useState<VADScore>({ valence: 0.5, arousal: 0.5, dominance: 0.5 });
  const [confidence, setConfidence] = useState(0);

  // ê°ì • ë³€í™” ì¶”ì´ë¥¼ ìœ„í•œ ìƒíƒœ ì¶”ê°€
  const [emotionHistory, setEmotionHistory] = useState<Array<{timestamp: number; emotion: string; valence: number}>>([]);
  const [showEmotionChart, setShowEmotionChart] = useState(false);

  // ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ìœ„í•œ ìƒíƒœ ì¶”ê°€
  const [displayedVAD, setDisplayedVAD] = useState<VADScore>({ valence: 0.5, arousal: 0.5, dominance: 0.5 });
  const [displayedConfidence, setDisplayedConfidence] = useState(0);
  const analysisIntervalRef = useRef<NodeJS.Timeout | null>(null);

  // API í˜¸ì¶œ ìƒíƒœ ê´€ë¦¬
  const [apiStatus, setApiStatus] = useState<'idle' | 'loading' | 'success' | 'error'>('idle');
  const [lastApiCall, setLastApiCall] = useState<Date | null>(null);

  // ë¹„ë””ì˜¤ í”„ë ˆì„ ìº¡ì²˜ í•¨ìˆ˜ (ìµœì í™”)
  const captureVideoFrame = useCallback(async (): Promise<File | null> => {
    if (!videoRef.current || !canvasRef.current) return null;
    
    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    
    if (!ctx) return null;
    
    // ìº”ë²„ìŠ¤ í¬ê¸°ë¥¼ ë¹„ë””ì˜¤ í¬ê¸°ì— ë§ì¶¤ (ì„±ëŠ¥ ìµœì í™”)
    const width = Math.min(video.videoWidth, 640); // ìµœëŒ€ 640pxë¡œ ì œí•œ
    const height = Math.min(video.videoHeight, 480); // ìµœëŒ€ 480pxë¡œ ì œí•œ
    
    canvas.width = width;
    canvas.height = height;
    
    // ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
    ctx.drawImage(video, 0, 0, width, height);
    
    // ìº”ë²„ìŠ¤ë¥¼ Blobìœ¼ë¡œ ë³€í™˜ (í’ˆì§ˆ ë‚®ì¶¤ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)
    return new Promise<File | null>((resolve) => {
      canvas.toBlob((blob) => {
        if (blob) {
          const file = new File([blob], `frame_${Date.now()}.jpg`, { type: 'image/jpeg' });
          resolve(file);
        } else {
          resolve(null);
        }
      }, 'image/jpeg', 0.6); // í’ˆì§ˆì„ 0.6ìœ¼ë¡œ ë‚®ì¶¤
    });
  }, []);

  // ì˜¤ë””ì˜¤ ì²­í¬ ìº¡ì²˜ í•¨ìˆ˜
  const captureAudioChunk = useCallback((): File | null => {
    if (!analyserRef.current || !isAudioOn) return null;
    
    // ê°„ë‹¨í•œ ì˜¤ë””ì˜¤ ë°ì´í„° ìº¡ì²˜ (ì‹¤ì œë¡œëŠ” MediaRecorder API ì‚¬ìš© ê¶Œì¥)
    const bufferLength = analyserRef.current.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    analyserRef.current.getByteFrequencyData(dataArray);
    
    // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜ (ì‹œë®¬ë ˆì´ì…˜)
    const audioBlob = new Blob([dataArray], { type: 'audio/wav' });
    return new File([audioBlob], `audio_${Date.now()}.wav`, { type: 'audio/wav' });
  }, [isAudioOn]);

  // ì‹¤ì œ ë°±ì—”ë“œ API í˜¸ì¶œ í•¨ìˆ˜
  const callRealtimeAnalysisAPI = useCallback(async (): Promise<EmotionAnalysis | null> => {
    try {
      setApiStatus('loading');
      setLastApiCall(new Date());
      
      const videoFrame = await captureVideoFrame();
      const audioChunk = captureAudioChunk();
      
      if (!videoFrame && !audioChunk) {
        console.warn('ìº¡ì²˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
        setApiStatus('error');
        return null;
      }

      const sessionId = `session_${Date.now()}`;
      const timestamp = new Date().toISOString();

      // íƒ€ì„ì•„ì›ƒì„ 2ì´ˆë¡œ ì¤„ì—¬ì„œ ë¹ ë¥¸ ì‘ë‹µ
      const result = await Promise.race([
        emotionRepository.analyzeRealtimeEmotion({
          videoFrame: videoFrame || undefined,
          audioChunk: audioChunk || undefined,
          sessionId,
          timestamp
        }),
        new Promise<null>((_, reject) => 
          setTimeout(() => reject(new Error('API íƒ€ì„ì•„ì›ƒ')), 2000)
        )
      ]);

      setApiStatus('success');
      return result;
    } catch (error) {
      console.error('ì‹¤ì‹œê°„ ë¶„ì„ API í˜¸ì¶œ ì‹¤íŒ¨:', error);
      setApiStatus('error');
      return null;
    }
  }, [captureVideoFrame, captureAudioChunk]);

  // ê°ì • í†µê³„ ê³„ì‚° í•¨ìˆ˜
  const getEmotionStats = () => {
    if (emotionHistory.length === 0) return null;
    
    const emotionCounts = emotionHistory.reduce((acc, entry) => {
      acc[entry.emotion] = (acc[entry.emotion] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    
    const mostFrequentEmotion = Object.entries(emotionCounts).reduce((a, b) => 
      emotionCounts[a[0]] > emotionCounts[b[0]] ? a : b
    )[0];
    
    const averageValence = emotionHistory.reduce((sum, entry) => sum + entry.valence, 0) / emotionHistory.length;
    
    return {
      mostFrequentEmotion,
      averageValence,
      totalSamples: emotionHistory.length
    };
  };

  const emotionStats = getEmotionStats();

  const animationFrameRef = useRef<number | null>(null);
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null);

  // ë…¹í™” íƒ€ì´ë¨¸ ì‹œì‘
  const startRecordingTimer = useCallback(() => {
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
    }
    recordingTimerRef.current = setInterval(() => {
      setRecordingTime(prev => prev + 1);
    }, 1000);
  }, []);

  // ë…¹í™” íƒ€ì´ë¨¸ ì •ì§€
  const stopRecordingTimer = useCallback(() => {
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }
  }, []);

  // ì‹œê°„ í¬ë§·íŒ…
  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
  const initializeMediaStream = useCallback(async () => {
    try {
      setCallStatus('connecting');
      setError(null);
      
      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        },
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      setStream(mediaStream);
      setPermissionGranted(true);
      setCallStatus('connected');
      
      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
      }

      // ì˜¤ë””ì˜¤ ë¶„ì„ ì´ˆê¸°í™”
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      }

      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 2048;
      analyserRef.current.smoothingTimeConstant = 0.8;

      microphoneRef.current = audioContextRef.current.createMediaStreamSource(mediaStream);
      microphoneRef.current.connect(analyserRef.current);

      return true;
    } catch (err) {
      console.error('ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” ì‹¤íŒ¨:', err);
      setError('ì¹´ë©”ë¼ë‚˜ ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      setCallStatus('ended');
      return false;
    }
  }, []);

  // ì‹¤ì‹œê°„ ê°ì • ë¶„ì„
  const analyzeEmotion = useCallback(() => {
    if (!isAnalyzing) return;

    let currentVoiceVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };
    let currentFacialVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };

    // ìŒì„± ë¶„ì„
    if (analyserRef.current && isAudioOn) {
      const bufferLength = analyserRef.current.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      const timeDataArray = new Uint8Array(bufferLength);

      analyserRef.current.getByteFrequencyData(dataArray);
      analyserRef.current.getByteTimeDomainData(timeDataArray);

      const volumeLevel = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength / 255;
      const pitchValue = calculatePitch(timeDataArray);
      const rateValue = calculateSpeechRate(timeDataArray);

      currentVoiceVAD = calculateVoiceVAD(volumeLevel, pitchValue, rateValue);
    }

    // í‘œì • ë¶„ì„ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
    if (isVideoOn) {
      currentFacialVAD = calculateFacialVAD();
    }

    // í†µí•© VAD ì ìˆ˜ ê³„ì‚°
    const integratedVAD = calculateIntegratedVAD(currentFacialVAD, currentVoiceVAD);
    const emotion = vadToEmotion(integratedVAD);
    const confidenceScore = calculateConfidence(currentFacialVAD, currentVoiceVAD);

    const emotionAnalysis: EmotionAnalysis = {
      id: `realtime_${Date.now()}`,
      userId: 'user123',
      timestamp: new Date().toISOString(),
      vadScore: integratedVAD,
      emotion,
      confidence: confidenceScore,
      mediaType: 'realtime',
      cbtFeedback: {
        cognitiveDistortion: 'ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘',
        challenge: 'í˜„ì¬ ê°ì • ìƒíƒœë¥¼ ê´€ì°°í•´ë³´ì„¸ìš”',
        alternative: 'ê°ì • ë³€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°›ì•„ë“¤ì´ì„¸ìš”',
        actionPlan: 'ì •ê¸°ì ì¸ ê°ì • ì²´í¬ë¥¼ í•´ë³´ì„¸ìš”'
      }
    };

    // ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
    setVoiceVAD(currentVoiceVAD);
    setFacialVAD(currentFacialVAD);
    setCurrentEmotion(emotionAnalysis);
    setConfidence(confidenceScore);

    if (onEmotionChange) {
      onEmotionChange(emotionAnalysis);
    }

    animationFrameRef.current = requestAnimationFrame(analyzeEmotion);
  }, [isAnalyzing, isAudioOn, isVideoOn, onEmotionChange]);

  // í”¼ì¹˜ ê³„ì‚°
  const calculatePitch = (timeData: Uint8Array): number => {
    let sum = 0;
    let count = 0;
    
    for (let i = 0; i < timeData.length; i++) {
      const value = (timeData[i] - 128) / 128;
      sum += Math.abs(value);
      count++;
    }
    
    return count > 0 ? sum / count : 0;
  };

  // ìŒì„± ì†ë„ ê³„ì‚°
  const calculateSpeechRate = (timeData: Uint8Array): number => {
    let zeroCrossings = 0;
    
    for (let i = 1; i < timeData.length; i++) {
      const prev = (timeData[i - 1] - 128) / 128;
      const curr = (timeData[i] - 128) / 128;
      
      if ((prev < 0 && curr >= 0) || (prev >= 0 && curr < 0)) {
        zeroCrossings++;
      }
    }
    
    return zeroCrossings / timeData.length;
  };

  // ìŒì„± VAD ê³„ì‚°
  const calculateVoiceVAD = (volume: number, pitch: number, rate: number): VADScore => {
    return {
      valence: Math.min(1, Math.max(0, 0.5 + (pitch - 0.5) * 0.3)),
      arousal: Math.min(1, Math.max(0, volume * 0.8 + rate * 0.2)),
      dominance: Math.min(1, Math.max(0, 0.5 + (volume - 0.5) * 0.4))
    };
  };

  // í‘œì • VAD ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
  const calculateFacialVAD = (): VADScore => {
    // ì‹¤ì œë¡œëŠ” MediaPipe Face Meshë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
    return {
      valence: 0.5 + (Math.random() - 0.5) * 0.2,
      arousal: 0.5 + (Math.random() - 0.5) * 0.2,
      dominance: 0.5 + (Math.random() - 0.5) * 0.2
    };
  };

  // í†µí•© VAD ê³„ì‚°
  const calculateIntegratedVAD = (facial: VADScore, voice: VADScore): VADScore => {
    return {
      valence: (facial.valence * 0.6 + voice.valence * 0.4),
      arousal: (facial.arousal * 0.4 + voice.arousal * 0.6),
      dominance: (facial.dominance * 0.5 + voice.dominance * 0.5)
    };
  };

  // VADë¥¼ ê°ì •ìœ¼ë¡œ ë³€í™˜
  const vadToEmotion = (vad: VADScore): string => {
    const { valence, arousal, dominance } = vad;
    
    if (valence > 0.7 && arousal > 0.7) return 'excited';
    if (valence > 0.7 && arousal < 0.3) return 'calm';
    if (valence > 0.6) return 'happy';
    if (valence < 0.4 && arousal > 0.7) return 'angry';
    if (valence < 0.4 && arousal < 0.3) return 'sad';
    if (dominance < 0.4 && arousal > 0.6) return 'anxious';
    
    return 'neutral';
  };

  // ì‹ ë¢°ë„ ê³„ì‚°
  const calculateConfidence = (facial: VADScore, voice: VADScore): number => {
    const facialConfidence = 0.8; // ì‹¤ì œë¡œëŠ” ì–¼êµ´ ì¸ì‹ ì‹ ë¢°ë„
    const voiceConfidence = 0.7; // ì‹¤ì œë¡œëŠ” ìŒì„± í’ˆì§ˆ ì‹ ë¢°ë„
    return (facialConfidence * 0.6 + voiceConfidence * 0.4);
  };

  // ê°ì • í‘œì‹œ ì»´í¬ë„ŒíŠ¸ ë©”ëª¨ì´ì œì´ì…˜
  const memoizedEmotionDisplay = useMemo(() => {
    if (!currentEmotion || !isAnalyzing) return null;

    return (
      <div className="absolute top-4 right-4 bg-black bg-opacity-80 text-white px-4 py-3 rounded-xl backdrop-blur-sm min-w-[280px]">
        <div className="space-y-3">
          {/* ë©”ì¸ ê°ì • í‘œì‹œ */}
          <div className="flex items-center justify-between">
            <div className="flex items-center space-x-3">
              <span className="text-3xl">{emotionEmojis[currentEmotion.emotion as keyof typeof emotionEmojis] || 'ğŸ˜'}</span>
              <div>
                <div className="font-semibold text-lg">
                  {currentEmotion.emotion === 'happy' ? 'ê¸°ì¨' : 
                   currentEmotion.emotion === 'sad' ? 'ìŠ¬í””' :
                   currentEmotion.emotion === 'angry' ? 'ë¶„ë…¸' :
                   currentEmotion.emotion === 'anxious' ? 'ë¶ˆì•ˆ' :
                   currentEmotion.emotion === 'excited' ? 'í¥ë¶„' :
                   currentEmotion.emotion === 'calm' ? 'í‰ì˜¨' :
                   currentEmotion.emotion === 'surprised' ? 'ë†€ëŒ' :
                   currentEmotion.emotion === 'neutral' ? 'ì¤‘ë¦½' : 'ê°ì • ë¶„ì„ ì¤‘'}
                </div>
                <div className="text-xs text-gray-300">
                  ì‹ ë¢°ë„: {Math.round(displayedConfidence * 100)}%
                </div>
              </div>
            </div>
            <div className="text-right">
              <div className="text-xs text-gray-300">ì‹¤ì‹œê°„</div>
              <div className="text-xs text-green-400">â—</div>
            </div>
          </div>

          {/* VAD ì ìˆ˜ í‘œì‹œ */}
          <div className="space-y-2">
            <div className="text-xs font-medium text-gray-300">ê°ì • ì„¸ë¶€ ë¶„ì„</div>
            <div className="grid grid-cols-3 gap-2 text-xs">
              <div className="bg-blue-500 bg-opacity-20 rounded p-2">
                <div className="font-medium text-blue-300">ê¸ì •ì„±</div>
                <div className="text-lg font-bold">{Math.round(displayedVAD.valence * 100)}%</div>
                <div className="w-full bg-blue-500 bg-opacity-30 rounded-full h-1 mt-1">
                  <div 
                    className="bg-blue-400 h-1 rounded-full transition-all duration-500" 
                    style={{ width: `${displayedVAD.valence * 100}%` }}
                  />
                </div>
              </div>
              <div className="bg-red-500 bg-opacity-20 rounded p-2">
                <div className="font-medium text-red-300">ê°ì„±ë„</div>
                <div className="text-lg font-bold">{Math.round(displayedVAD.arousal * 100)}%</div>
                <div className="w-full bg-red-500 bg-opacity-30 rounded-full h-1 mt-1">
                  <div 
                    className="bg-red-400 h-1 rounded-full transition-all duration-500" 
                    style={{ width: `${displayedVAD.arousal * 100}%` }}
                  />
                </div>
              </div>
              <div className="bg-purple-500 bg-opacity-20 rounded p-2">
                <div className="font-medium text-purple-300">ì§€ë°°ì„±</div>
                <div className="text-lg font-bold">{Math.round(displayedVAD.dominance * 100)}%</div>
                <div className="w-full bg-purple-500 bg-opacity-30 rounded-full h-1 mt-1">
                  <div 
                    className="bg-purple-400 h-1 rounded-full transition-all duration-500" 
                    style={{ width: `${displayedVAD.dominance * 100}%` }}
                  />
                </div>
              </div>
            </div>
          </div>

          {/* ê°ì • ê°•ë„ ë° ìƒíƒœ */}
          <div className="space-y-2">
            <div className="flex justify-between items-center">
              <span className="text-xs text-gray-300">ê°ì • ê°•ë„</span>
              <span className="text-xs font-medium">
                {displayedVAD.valence > 0.7 ? 'ë§¤ìš° ë†’ìŒ' :
                 displayedVAD.valence > 0.5 ? 'ë†’ìŒ' :
                 displayedVAD.valence > 0.3 ? 'ë³´í†µ' : 'ë‚®ìŒ'}
              </span>
            </div>
            <div className="flex justify-between items-center">
              <span className="text-xs text-gray-300">ì—ë„ˆì§€ ë ˆë²¨</span>
              <span className="text-xs font-medium">
                {displayedVAD.arousal > 0.7 ? 'ë§¤ìš° í™œë°œ' :
                 displayedVAD.arousal > 0.5 ? 'í™œë°œ' :
                 displayedVAD.arousal > 0.3 ? 'ë³´í†µ' : 'ì°¨ë¶„'}
              </span>
            </div>
          </div>

          {/* ì‹¤ì‹œê°„ í”¼ë“œë°± */}
          <div className="bg-white bg-opacity-10 rounded p-2">
            <div className="text-xs text-gray-300 mb-1">ì‹¤ì‹œê°„ í”¼ë“œë°±</div>
            <div className="text-xs">
              {currentEmotion.emotion === 'happy' && displayedVAD.valence > 0.7 ? 
                'ë§¤ìš° ê¸ì •ì ì¸ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ˜Š' :
               currentEmotion.emotion === 'sad' && displayedVAD.valence < 0.3 ? 
                'ìŠ¬í”ˆ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê´œì°®ìœ¼ì„¸ìš”? ğŸ˜”' :
               currentEmotion.emotion === 'angry' && displayedVAD.arousal > 0.7 ? 
                'ë¶„ë…¸í•œ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¬í˜¸í¡ì„ í•´ë³´ì„¸ìš” ğŸ˜¤' :
               currentEmotion.emotion === 'anxious' && displayedVAD.arousal > 0.6 ? 
                'ë¶ˆì•ˆí•œ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. í¸ì•ˆíˆ í˜¸í¡í•´ë³´ì„¸ìš” ğŸ˜°' :
               currentEmotion.emotion === 'calm' && displayedVAD.arousal < 0.4 ? 
                'í‰ì˜¨í•œ ìƒíƒœì…ë‹ˆë‹¤. ì¢‹ì€ ê°ì •ì„ ìœ ì§€í•˜ì„¸ìš” ğŸ˜Œ' :
               currentEmotion.emotion === 'excited' && displayedVAD.arousal > 0.6 ? 
                'í¥ë¯¸ì§„ì§„í•œ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰' :
               currentEmotion.emotion === 'surprised' ? 
                'ë†€ë€ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ˜²' :
                'ê°ì •ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'}
            </div>
          </div>

          {/* ê°ì • ë³€í™” ì¶”ì´ ì°¨íŠ¸ */}
          <div className="space-y-2">
            <div className="flex justify-between items-center">
              <span className="text-xs text-gray-300">ê°ì • ë³€í™” ì¶”ì´</span>
              <button
                onClick={() => setShowEmotionChart(!showEmotionChart)}
                className="text-xs text-blue-300 hover:text-blue-200 transition-colors"
              >
                {showEmotionChart ? 'ìˆ¨ê¸°ê¸°' : 'ë³´ê¸°'}
              </button>
            </div>
            {showEmotionChart && emotionHistory.length > 0 && (
              <div className="bg-white bg-opacity-5 rounded p-2">
                <div className="h-16 flex items-end justify-between space-x-1">
                  {emotionHistory.slice(-10).map((entry, index) => {
                    const height = Math.max(4, entry.valence * 60); // ìµœì†Œ 4px, ìµœëŒ€ 60px
                    const color = entry.valence > 0.7 ? 'bg-green-400' : 
                                 entry.valence > 0.5 ? 'bg-yellow-400' : 
                                 entry.valence > 0.3 ? 'bg-orange-400' : 'bg-red-400';
                    return (
                      <div key={index} className="flex-1 flex flex-col items-center">
                        <div 
                          className={`w-full ${color} rounded-t transition-all duration-300`}
                          style={{ height: `${height}px` }}
                        />
                        <div className="text-[8px] text-gray-400 mt-1">
                          {emotionEmojis[entry.emotion as keyof typeof emotionEmojis] || 'ğŸ˜'}
                        </div>
                      </div>
                    );
                  })}
                </div>
                <div className="text-[8px] text-gray-400 text-center mt-1">
                  ìµœê·¼ 10ì´ˆê°„ ê°ì • ë³€í™”
                </div>
              </div>
            )}
          </div>

          {/* ê°ì • í†µê³„ ì •ë³´ */}
          {emotionStats && emotionHistory.length > 5 && (
            <div className="bg-white bg-opacity-5 rounded p-2">
              <div className="text-xs text-gray-300 mb-2">ë¶„ì„ í†µê³„</div>
              <div className="space-y-1 text-xs">
                <div className="flex justify-between">
                  <span className="text-gray-400">ì£¼ìš” ê°ì •:</span>
                  <span className="font-medium">
                    {emotionStats.mostFrequentEmotion === 'happy' ? 'ê¸°ì¨' : 
                     emotionStats.mostFrequentEmotion === 'sad' ? 'ìŠ¬í””' :
                     emotionStats.mostFrequentEmotion === 'angry' ? 'ë¶„ë…¸' :
                     emotionStats.mostFrequentEmotion === 'anxious' ? 'ë¶ˆì•ˆ' :
                     emotionStats.mostFrequentEmotion === 'excited' ? 'í¥ë¶„' :
                     emotionStats.mostFrequentEmotion === 'calm' ? 'í‰ì˜¨' :
                     emotionStats.mostFrequentEmotion === 'surprised' ? 'ë†€ëŒ' :
                     emotionStats.mostFrequentEmotion === 'neutral' ? 'ì¤‘ë¦½' : 'ë¶„ì„ ì¤‘'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span className="text-gray-400">í‰ê·  ê¸ì •ì„±:</span>
                  <span className="font-medium">
                    {emotionStats.averageValence > 0.7 ? 'ë§¤ìš° ë†’ìŒ' :
                     emotionStats.averageValence > 0.5 ? 'ë†’ìŒ' :
                     emotionStats.averageValence > 0.3 ? 'ë³´í†µ' : 'ë‚®ìŒ'}
                    {' '}({Math.round(emotionStats.averageValence * 100)}%)
                  </span>
                </div>
                <div className="flex justify-between">
                  <span className="text-gray-400">ë¶„ì„ ìƒ˜í”Œ:</span>
                  <span className="font-medium">{emotionStats.totalSamples}ê°œ</span>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
    );
  }, [currentEmotion, isAnalyzing, displayedVAD, displayedConfidence, showEmotionChart, emotionHistory, emotionStats]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì´ˆê¸°í™”
  useEffect(() => {
    if (isActive) {
      initializeMediaStream();
    }
  }, [isActive, initializeMediaStream]);

  // ë¶„ì„ ë£¨í”„ ì‹œì‘/ì¤‘ì§€
  useEffect(() => {
    if (isAnalyzing) {
      const runAnalysis = async () => {
        // ì‹¤ì œ ë°±ì—”ë“œ API í˜¸ì¶œ ì‹œë„
        let apiResult: EmotionAnalysis | null = null;
        try {
          apiResult = await callRealtimeAnalysisAPI();
        } catch (error) {
          console.warn('ë°±ì—”ë“œ API í˜¸ì¶œ ì‹¤íŒ¨, ë¡œì»¬ ë¶„ì„ìœ¼ë¡œ í´ë°±:', error);
        }

        // API ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë¡œì»¬ ë¶„ì„
        if (apiResult) {
          // ë°±ì—”ë“œì—ì„œ ë°›ì€ ì‹¤ì œ ê²°ê³¼ ì‚¬ìš©
          const integratedVAD = apiResult.vadScore || { valence: 0.5, arousal: 0.5, dominance: 0.5 };
          const emotion = apiResult.emotion || 'neutral';
          const confidenceScore = apiResult.confidence || 0.5;

          // ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ìœ„í•œ ë³´ê°„ (ë” ë¹ ë¥¸ ë°˜ì‘)
          setDisplayedVAD(prev => ({
            valence: prev.valence * 0.5 + integratedVAD.valence * 0.5,
            arousal: prev.arousal * 0.5 + integratedVAD.arousal * 0.5,
            dominance: prev.dominance * 0.5 + integratedVAD.dominance * 0.5
          }));

          setDisplayedConfidence(prev => prev * 0.5 + confidenceScore * 0.5);

          // ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
          setCurrentEmotion(apiResult);
          setConfidence(confidenceScore);

          // ê°ì • íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ìµœê·¼ 20ê°œë§Œ ìœ ì§€)
          setEmotionHistory(prev => {
            const newHistory = [...prev, {
              timestamp: Date.now(),
              emotion,
              valence: integratedVAD.valence
            }];
            return newHistory.slice(-20);
          });

          if (onEmotionChange) {
            onEmotionChange(apiResult);
          }
        } else {
          // ë¡œì»¬ ë¶„ì„ (í´ë°±) - ë” ë¹ ë¥¸ ì²˜ë¦¬
          let currentVoiceVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };
          let currentFacialVAD: VADScore = { valence: 0.5, arousal: 0.5, dominance: 0.5 };

          // ìŒì„± ë¶„ì„
          if (analyserRef.current && isAudioOn) {
            const bufferLength = analyserRef.current.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            const timeDataArray = new Uint8Array(bufferLength);

            analyserRef.current.getByteFrequencyData(dataArray);
            analyserRef.current.getByteTimeDomainData(timeDataArray);

            const volumeLevel = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength / 255;
            const pitchValue = calculatePitch(timeDataArray);
            const rateValue = calculateSpeechRate(timeDataArray);

            currentVoiceVAD = calculateVoiceVAD(volumeLevel, pitchValue, rateValue);
          }

          // í‘œì • ë¶„ì„ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
          if (isVideoOn) {
            currentFacialVAD = calculateFacialVAD();
          }

          // í†µí•© VAD ì ìˆ˜ ê³„ì‚°
          const integratedVAD = calculateIntegratedVAD(currentFacialVAD, currentVoiceVAD);
          const emotion = vadToEmotion(integratedVAD);
          const confidenceScore = calculateConfidence(currentFacialVAD, currentVoiceVAD);

          // ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ìœ„í•œ ë³´ê°„ (ë” ë¹ ë¥¸ ë°˜ì‘)
          setDisplayedVAD(prev => ({
            valence: prev.valence * 0.5 + integratedVAD.valence * 0.5,
            arousal: prev.arousal * 0.5 + integratedVAD.arousal * 0.5,
            dominance: prev.dominance * 0.5 + integratedVAD.dominance * 0.5
          }));

          setDisplayedConfidence(prev => prev * 0.5 + confidenceScore * 0.5);

          const emotionAnalysis: EmotionAnalysis = {
            id: `realtime_${Date.now()}`,
            userId: 'user123',
            timestamp: new Date().toISOString(),
            vadScore: integratedVAD,
            emotion,
            confidence: confidenceScore,
            mediaType: 'realtime',
            cbtFeedback: {
              cognitiveDistortion: 'ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘',
              challenge: 'í˜„ì¬ ê°ì • ìƒíƒœë¥¼ ê´€ì°°í•´ë³´ì„¸ìš”',
              alternative: 'ê°ì • ë³€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°›ì•„ë“¤ì´ì„¸ìš”',
              actionPlan: 'ì •ê¸°ì ì¸ ê°ì • ì²´í¬ë¥¼ í•´ë³´ì„¸ìš”'
            }
          };

          // ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
          setCurrentEmotion(emotionAnalysis);
          setConfidence(confidenceScore);

          // ê°ì • íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ìµœê·¼ 20ê°œë§Œ ìœ ì§€)
          setEmotionHistory(prev => {
            const newHistory = [...prev, {
              timestamp: Date.now(),
              emotion,
              valence: integratedVAD.valence
            }];
            return newHistory.slice(-20);
          });

          if (onEmotionChange) {
            onEmotionChange(emotionAnalysis);
          }
        }
      };

      // 2ì´ˆë§ˆë‹¤ ë¶„ì„ ì‹¤í–‰ (ì„±ëŠ¥ ìµœì í™”)
      analysisIntervalRef.current = setInterval(runAnalysis, 2000);
      
      // ì´ˆê¸° ë¶„ì„ì€ 1ì´ˆ í›„ì— ì‹œì‘ (ì„±ëŠ¥ ìµœì í™”)
      setTimeout(() => {
        runAnalysis();
      }, 1000);
    } else {
      if (analysisIntervalRef.current) {
        clearInterval(analysisIntervalRef.current);
        analysisIntervalRef.current = null;
      }
    }

    return () => {
      if (analysisIntervalRef.current) {
        clearInterval(analysisIntervalRef.current);
        analysisIntervalRef.current = null;
      }
    };
  }, [isAnalyzing, isAudioOn, isVideoOn, callRealtimeAnalysisAPI, onEmotionChange]);

  // ë¶„ì„ í† ê¸€
  const toggleAnalysis = useCallback(() => {
    if (!permissionGranted) {
      setError('ë¨¼ì € ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsAnalyzing(prev => {
      const newState = !prev;
      if (newState) {
        setCallStatus('analyzing');
        startRecordingTimer();
        setShowGuide(false);
      } else {
        setCallStatus('paused');
        stopRecordingTimer();
      }
      return newState;
    });
  }, [permissionGranted, startRecordingTimer, stopRecordingTimer]);

  // ë¹„ë””ì˜¤ í† ê¸€
  const toggleVideo = useCallback(() => {
    if (stream) {
      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !isVideoOn;
        setIsVideoOn(!isVideoOn);
      }
    }
  }, [stream, isVideoOn]);

  // ì˜¤ë””ì˜¤ í† ê¸€
  const toggleAudio = useCallback(() => {
    if (stream) {
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !isAudioOn;
        setIsAudioOn(!isAudioOn);
      }
    }
  }, [stream, isAudioOn]);

  // ìƒë‹´ ì¢…ë£Œ
  const endCall = useCallback(() => {
    setCallStatus('ended');
    stopRecordingTimer();
    setIsAnalyzing(false);
    
    // ìƒë‹´ ì¢…ë£Œ í›„ ë¶„ì„ ê²°ê³¼ ìƒì„±
    if (currentEmotion && onEmotionChange) {
      const finalAnalysis: EmotionAnalysis = {
        ...currentEmotion,
        id: `consultation_${Date.now()}`,
        timestamp: new Date().toISOString(),
        mediaType: 'consultation',
        cbtFeedback: {
          cognitiveDistortion: 'ìƒë‹´ì„ í†µí•´ ê°ì • ìƒíƒœë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤',
          challenge: 'í˜„ì¬ ê°ì • ìƒíƒœë¥¼ ê°ê´€ì ìœ¼ë¡œ ë°”ë¼ë³´ì„¸ìš”',
          alternative: 'ê°ì • ë³€í™”ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ê³¼ì •ì…ë‹ˆë‹¤',
          actionPlan: 'ì •ê¸°ì ì¸ ê°ì • ì²´í¬ì™€ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤'
        }
      };
      onEmotionChange(finalAnalysis);
    }
    
    if (onCallEnd) {
      onCallEnd();
    }
  }, [onCallEnd, stopRecordingTimer, currentEmotion, onEmotionChange]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
  useEffect(() => {
    if (isActive) {
      initializeMediaStream();
    }
  }, [isActive, initializeMediaStream]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopRecordingTimer();
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        try {
          audioContextRef.current.close();
        } catch (error) {
          console.warn('AudioContext already closed:', error);
        }
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (analysisIntervalRef.current) {
        clearInterval(analysisIntervalRef.current);
      }
    };
  }, [stream, stopRecordingTimer]);

  if (!isActive) {
    return null;
  }

  return (
    <div className="relative w-full h-full bg-black rounded-lg overflow-hidden">
      {/* ë¹„ë””ì˜¤ ì˜ì—­ */}
      <div className="relative w-full h-full">
        <video
          ref={videoRef}
          className="w-full h-full object-cover transform scale-x-[-1]"
          style={{ 
            transform: 'scaleX(-1) !important',
            filter: 'hue-rotate(0deg)' // GPU ê°€ì†ì„ ìœ„í•œ ì¶”ê°€ ì†ì„±
          }}
          autoPlay
          muted
          playsInline
        />
        <canvas
          ref={canvasRef}
          className="absolute inset-0 w-full h-full pointer-events-none"
        />
        
        {/* ìƒíƒœ í‘œì‹œ ì˜¤ë²„ë ˆì´ */}
        <div className="absolute top-4 left-4 bg-black bg-opacity-70 text-white px-4 py-3 rounded-xl backdrop-blur-sm">
          <div className="flex items-center space-x-3">
            <div className={`w-3 h-3 rounded-full ${
              callStatus === 'connecting' ? 'bg-yellow-400 animate-pulse' :
              callStatus === 'connected' ? 'bg-green-400' :
              callStatus === 'analyzing' ? 'bg-red-400 animate-pulse' :
              callStatus === 'paused' ? 'bg-orange-400' :
              'bg-gray-400'
            }`} />
            <div className="text-sm font-medium">
              {callStatus === 'connecting' && 'ì—°ê²° ì¤‘...'}
              {callStatus === 'connected' && 'ì—°ê²°ë¨'}
              {callStatus === 'analyzing' && 'ë¶„ì„ ì¤‘'}
              {callStatus === 'paused' && 'ì¼ì‹œì •ì§€'}
              {callStatus === 'ended' && 'ì¢…ë£Œë¨'}
            </div>
          </div>
          {isAnalyzing && (
            <div className="mt-2 text-xs text-gray-300">
              ë…¹í™” ì‹œê°„: {formatTime(recordingTime)}
            </div>
          )}
          {/* API ìƒíƒœ í‘œì‹œ */}
          {isAnalyzing && (
            <div className="mt-2 flex items-center space-x-2">
              <div className={`w-2 h-2 rounded-full ${
                apiStatus === 'loading' ? 'bg-blue-400 animate-pulse' :
                apiStatus === 'success' ? 'bg-green-400' :
                apiStatus === 'error' ? 'bg-red-400' :
                'bg-gray-400'
              }`} />
              <div className="text-xs text-gray-300">
                {apiStatus === 'loading' && 'API í˜¸ì¶œ ì¤‘...'}
                {apiStatus === 'success' && 'ë°±ì—”ë“œ ë¶„ì„ ì™„ë£Œ'}
                {apiStatus === 'error' && 'ë¡œì»¬ ë¶„ì„ ì‚¬ìš© ì¤‘'}
                {apiStatus === 'idle' && 'ë¶„ì„ ëŒ€ê¸° ì¤‘'}
              </div>
            </div>
          )}
        </div>

        {/* í˜„ì¬ ê°ì • í‘œì‹œ - ë©”ëª¨ì´ì œì´ì…˜ëœ ë²„ì „ */}
        {memoizedEmotionDisplay}

        {/* ì‚¬ìš©ì ê°€ì´ë“œ */}
        {showGuide && callStatus === 'connected' && (
          <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 bg-black bg-opacity-80 text-white px-6 py-4 rounded-xl backdrop-blur-sm max-w-md text-center">
            <div className="space-y-3">
              <div className="text-lg font-semibold">ğŸ¥ ì˜ìƒ ìƒë‹´ ê°ì • ë¶„ì„</div>
              <div className="text-sm text-gray-300 space-y-2">
                <p>â€¢ ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤</p>
                <p>â€¢ "ì•Œê² ìŠµë‹ˆë‹¤" ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë°”ë¡œ ê°ì • ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤</p>
                <p>â€¢ ë¶„ì„ ì¤‘ì—ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì •ì´ í‘œì‹œë©ë‹ˆë‹¤</p>
                <p>â€¢ ì–¸ì œë“ ì§€ "ìƒë‹´ ì¢…ë£Œ"í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</p>
              </div>
              <button
                onClick={() => {
                  setShowGuide(false);
                  // ì¦‰ì‹œ ì¹´ë©”ë¼ ë°˜ì „ ì ìš©ì„ ìœ„í•œ ê°•ì œ ë¦¬ë Œë”ë§
                  if (videoRef.current) {
                    videoRef.current.style.transform = 'scaleX(-1) !important';
                  }
                  // ë°”ë¡œ ë¶„ì„ ì‹œì‘ (ë¶€ë“œëŸ½ê²Œ)
                  if (permissionGranted) {
                    setIsAnalyzing(true);
                    setCallStatus('analyzing');
                    startRecordingTimer();
                  }
                }}
                className="mt-4 px-4 py-2 bg-primary text-white rounded-lg text-sm hover:bg-primary-dark transition-colors"
              >
                ì•Œê² ìŠµë‹ˆë‹¤
              </button>
            </div>
          </div>
        )}

        {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
        {error && (
          <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 bg-red-500 text-white px-6 py-4 rounded-xl max-w-md text-center backdrop-blur-sm">
            <div className="space-y-2">
              <div className="text-lg font-semibold">âš ï¸ ì˜¤ë¥˜ ë°œìƒ</div>
              <div className="text-sm">{error}</div>
              <button
                onClick={() => setError(null)}
                className="mt-3 px-4 py-2 bg-white text-red-500 rounded-lg text-sm hover:bg-gray-100 transition-colors"
              >
                í™•ì¸
              </button>
            </div>
          </div>
        )}



        {/* ì»¨íŠ¸ë¡¤ ë°” */}
        <div className="absolute bottom-6 left-1/2 transform -translate-x-1/2 bg-black bg-opacity-70 rounded-full px-8 py-4 backdrop-blur-sm">
          <div className="flex items-center space-x-4">


            {/* ë¹„ë””ì˜¤ í† ê¸€ */}
            <ActionButton
              variant={isVideoOn ? 'secondary' : 'danger'}
              size="sm"
              onClick={toggleVideo}
              className="flex flex-col items-center space-y-1"
            >
              {isVideoOn ? <Video className="w-4 h-4" /> : <VideoOff className="w-4 h-4" />}
              <span className="text-xs">{isVideoOn ? 'ì¹´ë©”ë¼ ë„ê¸°' : 'ì¹´ë©”ë¼ ì¼œê¸°'}</span>
            </ActionButton>

            {/* ì˜¤ë””ì˜¤ í† ê¸€ */}
            <ActionButton
              variant={isAudioOn ? 'secondary' : 'danger'}
              size="sm"
              onClick={toggleAudio}
              className="flex flex-col items-center space-y-1"
            >
              {isAudioOn ? <Mic className="w-4 h-4" /> : <MicOff className="w-4 h-4" />}
              <span className="text-xs">{isAudioOn ? 'ë§ˆì´í¬ ë„ê¸°' : 'ë§ˆì´í¬ ì¼œê¸°'}</span>
            </ActionButton>

            {/* ìƒë‹´ ì¢…ë£Œ - ìƒë‹´ ì‹œì‘ í›„ì—ë§Œ í‘œì‹œ */}
            {isAnalyzing && (
              <ActionButton
                variant="danger"
                size="sm"
                onClick={endCall}
                className="flex flex-col items-center space-y-1"
              >
                <PhoneOff className="w-4 h-4" />
                <span className="text-xs">ìƒë‹´ ì¢…ë£Œ</span>
              </ActionButton>
            )}
          </div>
        </div>
      </div>
    </div>
  );
} 